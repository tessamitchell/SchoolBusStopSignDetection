{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM3HTvwdHZSpvfhXrywLaiB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tessamitchell/SchoolBusStopSignDetection/blob/main/FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Data Set Up"
      ],
      "metadata": {
        "id": "jrM8-ZbidwC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import datasets\n",
        "# Import train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.feature import haar_like_feature\n",
        "from skimage.feature import hog\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import xml.etree.ElementTree as ET"
      ],
      "metadata": {
        "id": "t23tlufndvA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X=data\n",
        "# y=data.labels\n",
        "\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "from google.colab import userdata\n",
        "\n",
        "rf = Roboflow(api_key=userdata.get('roboflow'))\n",
        "project = rf.workspace(\"myworkspace-hr4qa\").project(\"stop-sign-zn1kw-r77i3\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"voc\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NabnTVKOxyEt",
        "outputId": "c28b6e2e-6c7b-497b-f4b3-eb87567d1a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Stop-Sign-1 to voc:: 100%|██████████| 30287/30287 [00:02<00:00, 12217.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Stop-Sign-1 in voc:: 100%|██████████| 3196/3196 [00:00<00:00, 6801.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://chatgpt.com/share/692615ef-8958-8010-adfd-24ddd028c3e9\n",
        "def load_voc_annotation(xml_path):\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    boxes = []\n",
        "    for obj in root.findall(\"object\"):\n",
        "        bbox = obj.find(\"bndbox\")\n",
        "        xmin = int(bbox.find(\"xmin\").text)\n",
        "        ymin = int(bbox.find(\"ymin\").text)\n",
        "        xmax = int(bbox.find(\"xmax\").text)\n",
        "        ymax = int(bbox.find(\"ymax\").text)\n",
        "        boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "AlDpizPzw1vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "xml_paths = glob.glob(\"/content/your_dataset_name-1/train/*.xml\")\n",
        "# xml_paths = glob.glob(\"/content/*/*.xml\", recursive=True) # for train valid and test xml"
      ],
      "metadata": {
        "id": "8uZ9Vm6wFdVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "neg_images=[]"
      ],
      "metadata": {
        "id": "TVyjpa8JrFWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "7vnoRh0oBOoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AE0HLp8V4Dwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "WB_xkYRIBVTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sci-kit lbp extraction](https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_local_binary_pattern.html)"
      ],
      "metadata": {
        "id": "npddKX77TAoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_local_binary_pattern.html\n",
        "\n",
        "radius=3\n",
        "n_points=8*radius\n",
        "METHOD = 'uniform'\n",
        "def extract_lbp(img):\n",
        "  res=local_binary_pattern(img,n_points,radius,METHOD)\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "DdfEgO7D4CzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[scikit haar face extraction](https://scikit-image.org/docs/0.25.x/auto_examples/applications/plot_haar_extraction_selection_classification.html)\n",
        "\n",
        "[haar general additional link](https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_haar.html)"
      ],
      "metadata": {
        "id": "7jMDsHiAL5ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_types = ['type-2-x', 'type-2-y', 'type-3-x', 'type-3-y', 'type-4']\n",
        "def extract_haar(img):\n",
        "  haar=haar_like_feature(img,0,0,img.shape[0],img.shape[1])\n",
        "  return haar"
      ],
      "metadata": {
        "id": "iIK0FmkI4pP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hog(img):\n",
        "  feature,vis=hog(img,orientations=9, pixels_per_cell=(8, 8),cells_per_block=(2, 2))\n",
        "  return feature"
      ],
      "metadata": {
        "id": "7iJYWdgx4sB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img):\n",
        "  img=img[:,:,2] # extract red color channel, assume OpenCV BGR formatting\n",
        "  return np.concatenate([extract_lpb(img),extract_haar(img),extract_hog(img)])"
      ],
      "metadata": {
        "id": "_7-Xdp45YO6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features=[]\n",
        "y_labels=[]\n",
        "for window in images:\n",
        "  X_features.append(extract_features(window))\n",
        "  y_labels.append(1)\n",
        "\n",
        "for window in neg_images:\n",
        "  X_features.append(extract_features(window))\n",
        "  y_labels.append(0)"
      ],
      "metadata": {
        "id": "1t_gCN4d47AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training (Adaboost Cascade)"
      ],
      "metadata": {
        "id": "HlrVSzUA3zkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding these links here for any tabs I opened in my research that I might want to come back to\n",
        "\n",
        "[sklearn adaboost tutorial](https://www.datacamp.com/tutorial/adaboost-classifier-python)\n",
        "\n",
        "[another adaboost tutorial](https://www.kdnuggets.com/2022/10/implementing-adaboost-scikitlearn.html)\n",
        "\n",
        "[sklearn adaboost documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
        "\n",
        "[adaboost from scratch](https://medium.com/@enozeren/building-the-adaboost-model-from-scratch-with-python-db3a8a763484)\n",
        "\n",
        "[from scratch G4G](https://www.geeksforgeeks.org/machine-learning/implementing-the-adaboost-algorithm-from-scratch/)\n",
        "\n",
        "[sklearn pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)"
      ],
      "metadata": {
        "id": "vjTWR1uDLHn0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTdCU8qDSZe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lIbBH0042_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.3,random_state=42) # 70% training and 30% test"
      ],
      "metadata": {
        "id": "nsSy1uri44DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create adaboost classifer object\n",
        "abc = AdaBoostClassifier(n_estimators=50,\n",
        "                         learning_rate=1)\n",
        "# Train Adaboost Classifer\n",
        "model = abc.fit(X_train, y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "BbqRjMTV49c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sGY6oIUs5BSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Regions of Interest"
      ],
      "metadata": {
        "id": "Dt4rMwEAwDL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_windows(img):\n",
        "  return x,y,w,h"
      ],
      "metadata": {
        "id": "pgru0YPkAvGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testimages=[]\n",
        "positive_windows=[]\n",
        "for img in testimages:\n",
        "  windows=extract_windows(img)\n",
        "  for (x,y,w,h) in windows:\n",
        "    patch=img[x:x+h,y:y+w]\n",
        "    features=extract_features(patch)\n",
        "    if model.predict(features)==1:\n",
        "      positive_windows.append((img,patch,x,y,w,h))"
      ],
      "metadata": {
        "id": "rym42kke03x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Light Detection (Hough Circle Transform)"
      ],
      "metadata": {
        "id": "CY2dCIsq3nEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hough Circle Transform"
      ],
      "metadata": {
        "id": "KKT8Toc3w3FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# documentation https://docs.opencv.org/4.x/dd/d1a/group__imgproc__feature.html#ga47849c3be0d0406ad3ca45db65a25d2d\n",
        "def houghAndValidation(img):\n",
        "  blurred=cv.medianBlur(img,5)\n",
        "  minR=blurred.shape[1]/5\n",
        "  maxR=blurred.shape[1]/3\n",
        "  circles = cv.HoughCircles(blurred,cv.HOUGH_GRADIENT,1,20,\n",
        "                              param1=50,param2=30,minRadius=minR,maxRadius=maxR)\n",
        "\n",
        "  circles = np.uint16(np.around(circles))\n",
        "  # validation\n",
        "\n",
        "  for c in circles:\n",
        "    # compare radius with bounding box of stop sign\n",
        "\n",
        "    # get average intensity value and compare to red section of stop sign\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bCaxzU8x3yYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for win in positive_windows:\n",
        "  cw=canny(win[1])\n",
        "  hw=houghAndValidation(cw)\n"
      ],
      "metadata": {
        "id": "kPAUGb5IlVR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outputs"
      ],
      "metadata": {
        "id": "7nTD9mofdCVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
        "def drawBounds(img,circle,box):\n",
        "  cv.circle(img,(circle[0],circle[1]),circle[2],(255,0,0),2)\n",
        "  cv.rectangle(img,(box[0],box[1]),(box[2],box[3]),(0,255,0),2)"
      ],
      "metadata": {
        "id": "KloPWgtpdBvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}